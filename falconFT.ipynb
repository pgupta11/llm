{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a098d62-2bbb-466d-8b59-c11b3a156fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7a6307-72ba-4149-a5ba-5351f0245e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "#Load data set\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2d1918-f777-4ca1-8a26-cb9d4d01e1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Human: Can you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?### Assistant: Sure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and a dog picture could have very similar representations (their numbers would be close to each other), while at others two cat images may be represented far apart. In simple terms, the model wouldn\\'t be able to tell cats and dogs apart. This is where contrastive learning comes in.\\n\\nThe point of contrastive learning is to take pairs of samples (in this case images of cats and dogs), then train the model to \"pull\" representations of similar pairs (cat-cat or dog-dog) closer to each other and \"push\" representations of different pairs (cat-dog) apart. After doing this for a sufficient number of steps, your model will be able to produce unique, reliable representations for cats and dogs, in essence tell them apart.\\n\\nThis method is not limited to images, you can typically use it with any dataset that has similar and dissimilar data points.### Human: I didn\\'t understand how pulling and pushing works. What are we pulling or pushing? And how does it work in terms of code or maths?### Assistant: It has to do with a process called differentiation, which means finding a derivative: a function that tells us whether another function is going up or down at a given point. For example, the derivative of `f(x) = x` is `f\\'(x) = 1`, because it\\'s always going up at a 1:1 ratio. This can be done for a variety of functions; notably, if you know the derivatives of `f(x)` and `g(x)`, you can also get the derivative of `f(g(x))` using a formula called the chain rule. Neural networks happen to be made of differentiable functions, so we can take the derivative of parts or all of it.\\n\\nTo use this for \"pushing\" and \"pulling\", we\\'ll put two images through the neural network. Let\\'s say the images are of a cat and a dog, so we want to increase the distance between the two. We pick one neuron weight from the network and make it a variable `x`, then construct a function that calculates the output of the network based on it and all the other parameters; let\\'s call it `N(x)`. The distance between the cat and dog outputs would be `f(x) = N(cat) - N(dog)`. (Of course, the real output would have more than 1 dimension, but we\\'re simplifying.) We now want to nudge the weight such that it moves the two outputs slightly further apart. For that, we can simply take the derivative! If `f\\'(x)` is positive, that means that increasing the weight will move them further apart, so we should do that. If it\\'s negative, then it\\'ll move them closer, so we\\'ll want to slightly decrease the weight instead. Apply this to all the neurons enough times and your network will soon converge to a pretty good cat-dog separator!'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6876dfcb-2ace-42d2-8e0f-fdc6cf590ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read data from the JSON file into a list of dictionaries\n",
    "\n",
    "with open(\"../convLLM/generateQApairs/pairs.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "for item in data:\n",
    "    del item['reference_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe7694e-c0ca-46ec-b9da-13bb2fac9e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is the purpose of Flux Balance Analysis (FBA) models?',\n",
       "  'answer': 'The purpose of Flux Balance Analysis (FBA) models is to predict the metabolic behavior of an organism by quantifying the flow of metabolites through its metabolic network. FBA models are used to study and understand cellular metabolism, particularly in the context of predicting the growth rate or biomass yield of an organism under different conditions. By accounting for the stoichiometry of reactions and the constraints imposed by the availability of nutrients, FBA models can simulate the distribution of fluxes through metabolic pathways and identify optimal metabolic states that maximize the production of desired metabolites or biomass. FBA models are valuable tools in systems biology and can be used to guide metabolic engineering efforts, optimize bioprocesses, and explore the metabolic capabilities of organisms.'},\n",
       " {'question': 'What file formats can be used to upload FBA models into KBase?',\n",
       "  'answer': 'Flux Balance Analysis (FBA) models can be uploaded into KBase using three different file formats. These formats include:\\n\\n1. Systems Biology Markup Language (SBML): FBA models can be uploaded as SBML files with either the .sbml or .xml file extension. SBML is a standard format for representing computational models in systems biology.\\n\\n2. Excel: FBA models can also be uploaded as Excel files with the .xls extension. This allows users to create and edit FBA models using spreadsheet software.\\n\\n3. Tab-separated values (TSV): FBA models can be uploaded as TSV files with the .tsv extension. When using the TSV format, there will be two separate files corresponding to chemical compounds and reactions.\\n\\nIt is important to note that when uploading an FBA model in the TSV format, the model should be formatted correctly with the appropriate columns and data.\\n\\nIn summary, FBA models can be uploaded into KBase using SBML, Excel, or TSV file formats, providing users with flexibility in creating and importing their models.'},\n",
       " {'question': 'How many files are required when uploading an FBA model in the TSV format?',\n",
       "  'answer': 'When uploading an FBA model in the TSV format, there will be two files required. These files correspond to the chemical compounds and reactions in the model.'},\n",
       " {'question': 'Where can additional SBML FBA Models for various organisms be found?',\n",
       "  'answer': 'Additional SBML FBA Models for various organisms can be found at the following website: http://systemsbiology.ucsd.edu/Downloads.'},\n",
       " {'question': 'What is the recommended file format for creating a COBRA-compliant SBML file?',\n",
       "  'answer': 'The recommended file format for creating a COBRA-compliant SBML file is the Systems Biology Markup Language (SBML). SBML files can be uploaded into KBase as an FBA model. The SBML file can have either the .sbml or .xml file extension. To create a COBRA-compliant SBML file, you can refer to the SBML Level Three Specifications. Additionally, you can find more SBML FBA models for various organisms at the following link: http://systemsbiology.ucsd.edu/Downloads.'},\n",
       " {'question': 'Where can the SBML Level Three Specifications be found?',\n",
       "  'answer': 'The SBML Level Three Specifications can be found at the following location:\\n\\nhttp://sbml.org/Documents/Specifications'},\n",
       " {'question': 'What file extension is used for Excel files when uploading FBA models?',\n",
       "  'answer': 'The file extension used for Excel files when uploading Flux Balance Analysis (FBA) models is .xls.'},\n",
       " {'question': 'In the Excel format, where are the tables containing information about chemical compounds and reactions stored?',\n",
       "  'answer': 'In the Excel format, the tables containing information about chemical compounds and reactions are stored in two separate tabs. The tab for chemical compounds is named \"ModelCompounds\" and the tab for reactions is named \"ModelReactions.\"'},\n",
       " {'question': 'What are the required names for the tabs in the Excel file?',\n",
       "  'answer': 'The required names for the tabs in the Excel file are \"ModelCompounds\" and \"ModelReactions\".'},\n",
       " {'question': 'In the TSV format, how are the chemical compounds and reactions tables saved?',\n",
       "  'answer': 'In the TSV (Tab-Separated Values) file format, the chemical compounds and reactions tables are saved as two separate files. The chemical compounds table is saved as \"FBAModelCompounds.tsv\" and the reactions table is saved as \"FBAModelReactions.tsv\". These files contain tab-separated values, where each row represents a compound or reaction, and each column represents a specific attribute or property of the compound or reaction. The compounds table includes attributes such as id, name, formula, charge, and aliases, while the reactions table likely contains different attributes specific to reactions.'},\n",
       " {'question': 'What are the names of the files for the chemical compounds and reactions in the TSV format?',\n",
       "  'answer': 'In the TSV format, the chemical compounds table is saved as a file named \"FBAModelCompounds.tsv\" and the reactions table is saved as a file named \"FBAModelReactions.tsv\".'},\n",
       " {'question': 'What are the columns present in the \"FBAModelCompounds\" table?',\n",
       "  'answer': 'The \"FBAModelCompounds\" table contains the following columns:\\n\\n1. id: This column represents the compound identifier, which is a unique identifier for each compound in the table. It is used to reference the compound in other tables or models.\\n\\n2. name: This column stores the name of the chemical compound. It provides a human-readable description of the compound.\\n\\n3. formula: This column contains the chemical formula of the compound. The formula is represented using the Hill system, which is a widely used system for representing chemical formulas.\\n\\n4. charge: The charge column represents the formal charge of the molecule. It indicates the electrical charge of the compound, which can be positive, negative, or neutral.\\n\\n5. aliases: This column stores alternative names or aliases for the chemical compound. It provides additional names that can be used to refer to the compound.\\n\\nPlease note that this information is based on the given text and may not include all possible columns in the \"FBAModelCompounds\" table.'},\n",
       " {'question': 'What is the purpose of the \"id\" column in the \"FBAModelCompounds\" table?',\n",
       "  'answer': 'The \"id\" column in the \"FBAModelCompounds\" table serves as a unique identifier for each chemical compound listed in the table. It is used to uniquely identify and reference a specific compound within the FBA model. The \"id\" column allows for easy and unambiguous identification of compounds, which is crucial for performing various calculations and analyses in the FBA model.'},\n",
       " {'question': 'What is the purpose of the \"name\" column in the \"FBAModelCompounds\" table?',\n",
       "  'answer': 'The \"name\" column in the \"FBAModelCompounds\" table serves the purpose of storing the name of the chemical compound. It provides a human-readable identifier for each compound listed in the table. The names in this column are typically used to refer to the compounds in various analyses, calculations, and modeling processes.'},\n",
       " {'question': 'What is the purpose of the \"formula\" column in the \"FBAModelCompounds\" table?',\n",
       "  'answer': 'The \"formula\" column in the \"FBAModelCompounds\" table serves the purpose of providing the chemical formula of each compound. The chemical formula represents the types and numbers of atoms present in a molecule. In this table, the formula is written using the Hill system, which is a widely used method for representing chemical formulas. The formula column helps in identifying and understanding the composition of each compound in the FBA model.'},\n",
       " {'question': 'What is the purpose of the \"charge\" column in the \"FBAModelCompounds\" table?',\n",
       "  'answer': 'The \"charge\" column in the \"FBAModelCompounds\" table serves the purpose of indicating the formal charge of the chemical compounds. It provides information about the electrical charge of the molecule, which is an important characteristic in understanding its behavior and interactions in chemical reactions. The charge can be positive, negative, or neutral, and it influences the compound\\'s reactivity and participation in metabolic pathways.'},\n",
       " {'question': 'What is the purpose of the \"aliases\" column in the \"FBAModelCompounds\" table?',\n",
       "  'answer': 'The \"aliases\" column in the \"FBAModelCompounds\" table serves the purpose of providing alternative names for the chemical compounds listed in the table. These aliases are additional names or labels that can be used to refer to the compounds. They can be useful in cases where a compound may have multiple names or when different naming conventions are used in different contexts. The aliases column allows for better identification and referencing of the compounds, providing flexibility and accommodating different naming conventions or variations in compound names.'},\n",
       " {'question': 'What is the name of the table for the model reactions in the TSV format?',\n",
       "  'answer': 'In the TSV format, the table for the model reactions is named \"FBAModelReactions.tsv\".'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ff77d2-1279-45fd-bc33-17b89b7d614c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of Flux Balance Analysis (...</td>\n",
       "      <td>The purpose of Flux Balance Analysis (FBA) mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What file formats can be used to upload FBA mo...</td>\n",
       "      <td>Flux Balance Analysis (FBA) models can be uplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many files are required when uploading an ...</td>\n",
       "      <td>When uploading an FBA model in the TSV format,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where can additional SBML FBA Models for vario...</td>\n",
       "      <td>Additional SBML FBA Models for various organis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the recommended file format for creati...</td>\n",
       "      <td>The recommended file format for creating a COB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of Flux Balance Analysis (...   \n",
       "1  What file formats can be used to upload FBA mo...   \n",
       "2  How many files are required when uploading an ...   \n",
       "3  Where can additional SBML FBA Models for vario...   \n",
       "4  What is the recommended file format for creati...   \n",
       "\n",
       "                                              answer  \n",
       "0  The purpose of Flux Balance Analysis (FBA) mod...  \n",
       "1  Flux Balance Analysis (FBA) models can be uplo...  \n",
       "2  When uploading an FBA model in the TSV format,...  \n",
       "3  Additional SBML FBA Models for various organis...  \n",
       "4  The recommended file format for creating a COB...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7a6c13-200a-45ad-8935-c90dc6f00ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the purpose of Flux Balance Analysis (FBA) models? The purpose of Flux Balance Analysis (FBA) models is to predict the metabolic behavior of an organism by quantifying the flow of metabolites through its metabolic network. FBA models are used to study and understand cellular metabolism, particularly in the context of predicting the growth rate or biomass yield of an organism under different conditions. By accounting for the stoichiometry of reactions and the constraints imposed by the availability of nutrients, FBA models can simulate the distribution of fluxes through metabolic pathways and identify optimal metabolic states that maximize the production of desired metabolites or biomass. FBA models are valuable tools in systems biology and can be used to guide metabolic engineering efforts, optimize bioprocesses, and explore the metabolic capabilities of organisms.\n"
     ]
    }
   ],
   "source": [
    "print(df['question'][0],df['answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29aa64e8-f2a1-4bb4-9ad5-f41aa456468d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been saved to output.json\n"
     ]
    }
   ],
   "source": [
    "# Save the data to a JSON file\n",
    "with open(\"data.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print(\"JSON data has been saved to output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf224511-084d-445e-ba95-2d31249d0efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9917b77ab54e1ead2e60de0ea1692b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dae146fcb4f41e185b5b47a8b83c4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b3c9c020bd46c48a7cc4d647aa852b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"json\",data_files=\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d778b2f7-bbff-4c13-ad64-b30565f7fe55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What file formats can be used to upload FBA models into KBase?',\n",
       " 'answer': 'Flux Balance Analysis (FBA) models can be uploaded into KBase using three different file formats. These formats include:\\n\\n1. Systems Biology Markup Language (SBML): FBA models can be uploaded as SBML files with either the .sbml or .xml file extension. SBML is a standard format for representing computational models in systems biology.\\n\\n2. Excel: FBA models can also be uploaded as Excel files with the .xls extension. This allows users to create and edit FBA models using spreadsheet software.\\n\\n3. Tab-separated values (TSV): FBA models can be uploaded as TSV files with the .tsv extension. When using the TSV format, there will be two separate files corresponding to chemical compounds and reactions.\\n\\nIt is important to note that when uploading an FBA model in the TSV format, the model should be formatted correctly with the appropriate columns and data.\\n\\nIn summary, FBA models can be uploaded into KBase using SBML, Excel, or TSV file formats, providing users with flexibility in creating and importing their models.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95aaf5ec-ce60-4c92-a2dd-a517a0115056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "    <human>: {data_point['question']}\n",
    "    <assistant>: {data_point['answer']}\n",
    "    \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5363c95-d70e-48bd-9a4e-66db667c9f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23a2a05b74f41c398aee95c35bd2bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map = \"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e1c9ce4-d834-490f-b36a-6c4f247bf16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6992f74e-c70c-48ba-b6f5-088059ec69f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0342b156-228d-43d4-9fc6-3c4f04990921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenizer(full_prompt,padding=True,truncation=True)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e34b9fc-045a-4337-8194-b20617f3978a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd275cb53efa4a8f8cf5f518fdedc1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data['train'].shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9bf2ade-4bcc-4f9a-b6ca-2cdb7bd0665d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 18\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc930cb-2f57-4e68-a687-785122ba9939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c6fd1a8-8027-45a1-8501-e400bb32b264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 130547712 || all params: 3739292544 || trainable%: 3.4912409356543783\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"query_key_value\",\n",
    "        \"dense\",\n",
    "        \"dense_h_to_4h\",\n",
    "        \"dense_4h_to_h\",\n",
    "    ]\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "497a533b-5941-404f-973e-33f5e307e980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "per_device_train_batch_size = 1\n",
    "gradient_accumulation_steps = 4\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 10\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 500\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    #group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0786390e-b901-410b-813a-2d3d8e9b4643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 512\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=data,\n",
    "#     peft_config=peft_config,\n",
    "#     dataset_text_field=\"text\",\n",
    "#     max_seq_length=max_seq_length,\n",
    "#     tokenizer=tokenizer,\n",
    "#     args=training_arguments,\n",
    "# )\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data,\n",
    "    data_collator = transformers.DataCollatorForLanguageModeling(tokenizer,mlm=False),\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "704f6c00-e52d-467d-9735-c5e82bd556f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd70c398-673a-46e4-a55a-948995dc6b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 13:40, Epoch 111/125]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.038100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.034900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.033800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.034500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.035200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.12523856300115585, metrics={'train_runtime': 822.6604, 'train_samples_per_second': 2.431, 'train_steps_per_second': 0.608, 'total_flos': 4559091949294848.0, 'train_loss': 0.12523856300115585, 'epoch': 111.11})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f93cae5d-4d57-4313-abc5-0110f86089f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): PeftModelForCausalLM(\n",
       "      (base_model): LoraModel(\n",
       "        (model): RWForCausalLM(\n",
       "          (transformer): RWModel(\n",
       "            (word_embeddings): Embedding(65024, 4544)\n",
       "            (h): ModuleList(\n",
       "              (0-31): 32 x DecoderLayer(\n",
       "                (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "                (self_attention): Attention(\n",
       "                  (maybe_rotary): RotaryEmbedding()\n",
       "                  (query_key_value): Linear4bit(\n",
       "                    in_features=4544, out_features=4672, bias=False\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=4544, out_features=64, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=64, out_features=4672, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dense): Linear4bit(\n",
       "                    in_features=4544, out_features=4544, bias=False\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=4544, out_features=64, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=64, out_features=4544, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (mlp): MLP(\n",
       "                  (dense_h_to_4h): Linear4bit(\n",
       "                    in_features=4544, out_features=18176, bias=False\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=4544, out_features=64, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=64, out_features=18176, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dense_4h_to_h): Linear4bit(\n",
       "                    in_features=18176, out_features=4544, bias=False\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=18176, out_features=64, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=64, out_features=4544, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19dbac4e-48f9-447e-a45c-31a641d1902e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c21e65a-dc1c-4904-8c1b-5b3807cecb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51948de0d35545c0b466ca1559606632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c4c0736-a29d-43ea-9544-f6428f6b3bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/pgupta2023/falcon-7b-ft-prac/commit/1f58dd084740474afd94c31d888da0da81b33ca6', commit_message='Upload model', commit_description='', oid='1f58dd084740474afd94c31d888da0da81b33ca6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"pgupta2023/falcon-7b-ft-prac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed6610-b3ff-4407-965b-02d7aed92c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
