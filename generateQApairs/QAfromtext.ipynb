{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8045b8f9-6629-4429-aa9a-c32e0edf17da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68a2090-9a13-4ba7-a313-62df35e495b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import JSONLoader, DirectoryLoader, UnstructuredHTMLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7871f892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895c3ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8415e0d2-157d-42f2-8279-bb7f85dfaea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Key for llm used to generate the QA apirs\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254a4d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "html_dir_loader = DirectoryLoader('../kbasedocs/', glob=\"**/[!.]*.html\", loader_cls=UnstructuredHTMLLoader)\n",
    "data_html = html_dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f0b7f6-849b-4675-b20e-9299124a054d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e8227f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    ")\n",
    "documents_html = text_splitter.split_documents(data_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f5955c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt used to extract questions\n",
    "extraction_system_prompt=\"You are an expert user extracting information to quiz people on documentation. You will be passed a page extracted from the documentation, write a numbered list of questions that can be answered based *solely* on the given text.\"\n",
    "def create_extraction_conversation_messages(text):\n",
    "    \"\"\"\n",
    "    Takes a piece of text and returns a list of messages designed to extract questions from the text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text for which questions are to be extracted.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of messages that set up the context for extracting questions.\n",
    "    \"\"\"\n",
    "    # Create a system message setting the context for the extraction task\n",
    "    context_message = SystemMessage(content=extraction_system_prompt)\n",
    "    \n",
    "    # Create a human message containing the input text\n",
    "    input_text_message = HumanMessage(content=text)\n",
    "    \n",
    "    # Return the list of messages to be used in the extraction conversation\n",
    "    return [context_message, input_text_message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e4da0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_questions_from_output(output):\n",
    "    \"\"\"\n",
    "    Takes a numbered list of questions as a string and returns them as a list of strings.\n",
    "    The input might have prefixes/suffixes that are not questions or incomplete questions.\n",
    "\n",
    "    Args:\n",
    "        output (str): A string containing a numbered list of questions.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of extracted questions as strings.\n",
    "    \"\"\"\n",
    "    # Define a regex pattern to match questions (lines starting with a number followed by a dot and a space)\n",
    "    question_pattern = re.compile(r\"^\\s*\\d+\\.\\s*(.+)$\", re.MULTILINE)\n",
    "\n",
    "    # Find all the questions matching the pattern in the input text\n",
    "    questions = question_pattern.findall(output)\n",
    "\n",
    "    # Check if the last question is incomplete (does not end with punctuation or a parenthesis)\n",
    "    if (len(questions) > 0) and (not re.search(r\"[.!?)]$\", questions[-1].strip())):\n",
    "        print(f\"WARNING: Popping incomplete question: '{questions[-1]}'\")\n",
    "        questions.pop()\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c300011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_questions_and_ref(ref_text):\n",
    "    result = create_extraction_conversation_messages(ref_text)\n",
    "    reference_text = result[1].content\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "    output = llm(result)\n",
    "    # Extracting questions\n",
    "    questions = output.content.split('\\n')\n",
    "\n",
    "    # Remove empty elements and leading/trailing spaces\n",
    "    questions = [question.strip() for question in questions if question.strip()]\n",
    "    # Extracting questions and removing numbers\n",
    "    questions = re.findall(r'\\d+\\.\\s*(.*)', output.content)\n",
    "    return reference_text, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b43aa91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt used to answer a question\n",
    "answering_system_prompt=\"You are an expert user answering questions. You will be passed a page extracted from a documentation and a question. Generate a comprehensive and informative answer to the question based *solely* on the given text.\"\n",
    "\n",
    "\n",
    "def create_answering_conversation_messages(question, text):\n",
    "    \"\"\"\n",
    "    Takes a question and a text and returns a list of messages designed to answer the question based on the text.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The question to be answered.\n",
    "        text (str): The text containing information for answering the question.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of messages that set up the context for answering the question.\n",
    "    \"\"\"\n",
    "    # Create a system message setting the context for the answering task\n",
    "    context_message = SystemMessage(content=answering_system_prompt)\n",
    "    \n",
    "    # Create a human message containing the input text\n",
    "    input_text_message = HumanMessage(content=text)\n",
    "    \n",
    "    # Create a human message containing the question to be answered\n",
    "    input_question_message = HumanMessage(content=question)\n",
    "    \n",
    "    # Return the list of messages to be used in the answering conversation\n",
    "    \n",
    "    return [context_message, input_text_message, input_question_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a9b249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions=[]\n",
    "reference_text=[]\n",
    "for item in documents_html[305:306]:\n",
    "    rt, q = extract_questions_and_ref(item.page_content)\n",
    "    reference_text.append(rt)\n",
    "    questions.append(q)\n",
    "#questions = list(chain(*questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a851eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='gut environment, exploring the trade-offs in information provided by applying each metabolic flux modeling approach. Overall, we conclude that no single community modeling approach is better than the others, and often there is much to be gained by applying multiple approaches synergistically when exploring the ecology of a microbial community.', metadata={'source': '../kbasedocs/workflows_metabolic-models_metabolic-flux-models.html'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_html[305:306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce0aa7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_answers(questions,ref_text):\n",
    "    # Create the input messages for the chat model\n",
    "\n",
    "    answers=[]\n",
    "    for item in questions:\n",
    "        message = create_answering_conversation_messages(item, ref_text)\n",
    "        answer = llm(message)\n",
    "        answers.append(answer.content)\n",
    "        # run the chat model with the input messages\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "345046b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers=[]\n",
    "for q,r in zip(questions,reference_text):\n",
    "    answers.append(extract_answers(q,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d03925b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine questions and answers into a list of dictionaries\n",
    "data = []\n",
    "for ref_text, q_list, a_list in zip(reference_text, questions, answers):\n",
    "    for q, a in zip(q_list, a_list):\n",
    "        data.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": a,\n",
    "            \"reference_text\": ref_text\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc1d7450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the focus of the document?', 'answer': 'The focus of the document is on exploring different metabolic flux modeling approaches in the context of the gut environment and discussing the trade-offs in the information provided by each approach. The document emphasizes that no single community modeling approach is superior to others and suggests that combining multiple approaches can be beneficial when studying the ecology of a microbial community.', 'reference_text': 'gut environment, exploring the trade-offs in information provided by applying each metabolic flux modeling approach. Overall, we conclude that no single community modeling approach is better than the others, and often there is much to be gained by applying multiple approaches synergistically when exploring the ecology of a microbial community.'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2cbe825",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to pairs_n3.json.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_filepath = 'pairs_n3.json'\n",
    "with open(output_filepath, 'w') as output_file:\n",
    "    json.dump(data, output_file, indent=4)\n",
    "    print(f\"Results have been saved to {output_filepath}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a0bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
